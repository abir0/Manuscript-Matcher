{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Notebook Setup"
      ],
      "metadata": {
        "id": "4LqG_dN9GBYC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "_cExHjY4CKwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch transformers[sentencepiece] fastbook fastai ohmeow-blurr nbdev"
      ],
      "metadata": {
        "id": "uXWSGI6gCbXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnxruntime onnx"
      ],
      "metadata": {
        "id": "jwAlGXlzUEXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification, AutoConfig\n",
        "from fastai.text.all import *\n",
        "from blurr.text.data.all import *\n",
        "from blurr.text.modeling.all import *"
      ],
      "metadata": {
        "id": "asVpledMCgiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "bjuEHD62USq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "P0YDHcgGClMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Manuscript-Matcher"
      ],
      "metadata": {
        "id": "D0ou8_yUCoXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data"
      ],
      "metadata": {
        "id": "HbnBTOuhCwTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Manuscript-Matcher/labelled_data.csv')"
      ],
      "metadata": {
        "id": "u5Z9kZ3M-ufj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "asjc_df = pd.read_csv('/content/drive/MyDrive/Manuscript-Matcher/asjc_codes.csv')\n",
        "asjc_df = asjc_df[['Code', 'ASJC category']]"
      ],
      "metadata": {
        "id": "nOAcHQ9xhkay"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label Encoding"
      ],
      "metadata": {
        "id": "FMo6BDR058UA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "code2cat = dict(zip(asjc_df['Code'], asjc_df['ASJC category']))\n",
        "cat2code = dict(zip(asjc_df['ASJC category'], asjc_df['Code']))"
      ],
      "metadata": {
        "id": "cLnRXbNhhkm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_values(lst):\n",
        "    counts = {}\n",
        "    for sublist in lst:\n",
        "        sublist = eval(sublist)\n",
        "        for item in sublist:\n",
        "            if item in counts:\n",
        "                counts[item] += 1\n",
        "            else:\n",
        "                counts[item] = 1\n",
        "    return counts"
      ],
      "metadata": {
        "id": "uFPTMWj3d9rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "revised_categories_count = count_values(df.revised_categories.to_list())\n",
        "categories_encoding = {code2cat[key]: idx for idx, (key, value) in enumerate(revised_categories_count.items())}"
      ],
      "metadata": {
        "id": "CsTrXEqpdeoK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train Test Split"
      ],
      "metadata": {
        "id": "Q_IYkHwsjE97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = RandomSplitter(valid_pct=0.1, seed=42)\n",
        "train_ids, valid_ids = splitter(df)\n",
        "len(train_ids), len(valid_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEmUvFW3Vhj7",
        "outputId": "74d6b5b3-23c5-41df-faf2-78729946e8db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28275, 3141)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_df = df.loc[valid_ids]\n",
        "# valid_df.head()"
      ],
      "metadata": {
        "id": "hN7ZEBVhVikV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "D0FWLZudtmRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"models/manuscript-matcher-stage-1.pkl\"\n",
        "learner_inf = load_learner(model_path)"
      ],
      "metadata": {
        "id": "-FqH9sSptqR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learner_inf.blurr_predict(\"In vitro blood cell viability profiling of polymers used in molecular assembly.\")"
      ],
      "metadata": {
        "id": "c_F6yn4QtrMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learner_inf.blurr_predict(\"In vitro blood cell viability profiling of polymers used in molecular assembly.\")[0]['labels']"
      ],
      "metadata": {
        "id": "r-9pEO7OtrPm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a286f2bb-3931-4c45-dde3-10837aae01aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Organic Chemistry', 'Polymers and Plastics']"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## F1 Evaluation"
      ],
      "metadata": {
        "id": "fe1UAhHxZ4jW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "def metric_measures(test_df, preds):\n",
        "\n",
        "  targets = [np.asarray(eval(target)) for target in test_df.label.to_list()]\n",
        "  outputs = [np.asarray(pred) for pred in preds]\n",
        "\n",
        "  accuracy = metrics.accuracy_score(targets, outputs)\n",
        "  f1_score_micro = metrics.f1_score(targets, outputs, average='micro')\n",
        "  f1_score_macro = metrics.f1_score(targets, outputs, average='macro')\n",
        "\n",
        "  print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "  print(f\"F1 Score (Macro) = {f1_score_macro}\")\n",
        "\n",
        "  return"
      ],
      "metadata": {
        "id": "Ln7YyH6uZ1XB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "for idx, row in tqdm(valid_df.iterrows(), total=len(valid_df)):\n",
        "  desc = row['text']\n",
        "  labels = learner_inf.blurr_predict(desc)[0]['labels']\n",
        "  pred_cats = [0] * len(categories_encoding)\n",
        "  for label in labels:\n",
        "    pred_cats[categories_encoding[label]] = 1\n",
        "  preds.append(pred_cats)\n",
        "\n",
        "preds[0][:20]"
      ],
      "metadata": {
        "id": "QA8pyNtYZ1bv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric_measures(valid_df, preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC06jjrBZ1fj",
        "outputId": "587f2c73-0e43-4923-d783-14cc5a1d3b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score (Micro) = 0.7067603922589603\n",
            "F1 Score (Macro) = 0.5970682523875122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ONNX Quantization"
      ],
      "metadata": {
        "id": "6ctn4p5daBoL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"models/manuscript-matcher-stage-1.pkl\"\n",
        "learner_inf = load_learner(model_path)"
      ],
      "metadata": {
        "id": "QdL3tLO-Z_Ln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = learner_inf.model.hf_model.eval()\n",
        "\n",
        "torch.onnx.export(\n",
        "    classifier,\n",
        "    torch.LongTensor([[0] * 512]),\n",
        "    'models/manuscript-matcher.onnx',\n",
        "    input_names=['input_ids'],\n",
        "    output_names=['output'],\n",
        "    opset_version=13,\n",
        "    dynamic_axes={\n",
        "        'input_ids': {0: 'batch_size', 1: 'sequence_len'},\n",
        "        'output': {0: 'batch_size'}\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "4w-ifTe0aKXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "\n",
        "onnx_model_path = 'models/manuscript-matcher.onnx'\n",
        "quantized_onnx_model_path = 'models/manuscript-matcher-quantized.onnx'\n",
        "\n",
        "quantize_dynamic(\n",
        "    onnx_model_path,\n",
        "    quantized_onnx_model_path,\n",
        "    weight_type=QuantType.QUInt8,\n",
        ")"
      ],
      "metadata": {
        "id": "wXRTlPKUaKZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ONNX Inference"
      ],
      "metadata": {
        "id": "b6IYZbVeaSV9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import onnxruntime as rt\n",
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilroberta-base\")\n",
        "\n",
        "class_labels = list(categories_encoding.keys())\n",
        "\n",
        "inf_session = rt.InferenceSession('models/manuscript-matcher-quantized.onnx')\n",
        "input_name = inf_session.get_inputs()[0].name\n",
        "output_name = inf_session.get_outputs()[0].name"
      ],
      "metadata": {
        "id": "PNeWCwKmabiG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "for idx, row in tqdm(valid_df.iterrows(), total=valid_df.shape[0]):\n",
        "  text = row['text']\n",
        "  input_ids = tokenizer(text)['input_ids'][:512]\n",
        "\n",
        "  probs = inf_session.run([output_name], {input_name: [input_ids]})[0]\n",
        "  probs = torch.FloatTensor(probs)\n",
        "\n",
        "  masks = torch.sigmoid(probs) >= 0.5\n",
        "  labels = [class_labels[idx] for idx, mask in enumerate(masks[0]) if mask]\n",
        "\n",
        "  pred_cats = [0] * len(categories_encoding)\n",
        "  for label in labels:\n",
        "    pred_cats[categories_encoding[label]] = 1\n",
        "  preds.append(pred_cats)"
      ],
      "metadata": {
        "id": "0Vs3S9moab6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric_measures(valid_df, preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZLziB7aadwu",
        "outputId": "afea1b4e-265e-4579-9fea-4658d7e39167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Score (Micro) = 0.6891020052310375\n",
            "F1 Score (Macro) = 0.5803489754056876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5BVtSYd1vCQt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}